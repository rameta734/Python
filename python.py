# -*- coding: utf-8 -*-
"""Another copy of Pandas Operations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bca7ZfdnWbfs9jmULARjdVnw9YZ2RMZe

## **Yesterday, we learnt a little about the very useful library Pandas widely used for Data Analysis. It is time to put the many utilities of this library in front of our eyes. We will be performing following manipulations and exploration of our data:**

* ### Indexing and slicing operations
* ### Manipulating columns
* ### Exploring unique and missing values

**Link to the Dataset : -** https://drive.google.com/drive/folders/1EaOr6hdRDkEvy31ABSnH3iyClM4tRmS1
"""

# Import pandas package
import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""## Let us read our data first"""

# loading csv File
file_path = '/content/drive/MyDrive/AlmaBetter/Cohort Nilgiri/Module 1/Week 3/Day 3/imdb_data.csv'
df=pd.read_csv(file_path)

df.shape

df.head()

df.tail(10)

df.info()

"""# <u>**<code>describe()</code>**</u>

## This method gives the overall descriptive summary of the dataframe. This works only for numerical columns
"""

df.describe()

"""# <u>**Indexing and Slicing**</u>"""

df.head()

"""## **<code>iloc</code>** gets rows (or columns) at particular positions in the index (so it only takes integers)."""

# Let us get a subset which consists of first 8 rows and first 4 columns
df.iloc[:,-3:]

"""## **<code>loc</code>** gets rows (or columns) with particular labels from the index."""

# Now let us subset our dataframe in which we want to have first 8 rows identified with their rows labels and some named columns
df.loc[50:60,['budget','genres','runtime']]

df.loc[:,['budget','genres','runtime']]

df[0:10]

df[['original_language','release_date','cast']]

df.columns

"""## <b>In fact we can also perform boolean indexing on our dataframe</b>"""

df['original_language'] == 'en'

# Boolean Indexing
english_movies = df[df['original_language'] == 'en']
english_movies.head()

english_movies.shape

non_english_movies = df[df['original_language'] != 'en']
non_english_movies.head()

long_movies = df[df['runtime'] > 120]
long_movies[['title','cast']]

"""## Infact we can match conditions for mutliple columns"""

long_movies = df[df['runtime'] > 120]

long_movies.tail()

(df['original_language']=='en') & (df['runtime'] > 120)

long_english_movies = df[(df['original_language']=='en') & (df['runtime'] > 120)]
long_english_movies.head()

long_english_movies.shape

"""# <u>**Next let us see how we can manipulate columns**</u>"""

df.shape

"""## **Let's say if you wanted a new column whose values were half the movie runtime**"""

df['runtime']

# Add new column which is just half the runtime
df['half_runtime'] = df['runtime'] * 0.5

df.head()

"""## We can also create a new column by adding two existing columns"""

# Creating another new column by subtracting/adding two existing columns
df['movie_profit'] = df['revenue'] - df['budget']

df.head()

"""## **Next, we can also drop some columns which we want to drop**"""

# Remove column
df.drop(['id'], axis = 1, inplace=True)

df.head()

df.describe()

"""## You can drop  multiple columns at once too."""

df.drop(['half_runtime','poster_path'],axis=1,inplace=True)

df.drop(['crew'], axis = 1, inplace=True)

df.head()

"""## **We can do a lot of basic operations as well**"""

# Find the sum of values in a column
df['budget'].sum()

# What if there is a null value
df.loc[:1,'revenue'] = np.nan

df.iloc[:5]

df.set_index('imdb_id', inplace=True)

df.head()

df.iloc[:3]

df.loc[['tt2637294','tt0368933']]

df.head()

df['runtime'].sum()

print(f" The shortest movie length is {df['runtime'].min()}")
print(f" The largest movie length is {df['runtime'].max()}")

df[df['runtime']== 0.0]

"""# **<code>apply()</code>** method applies a function to every row in a pandas dataframe"""

# Suppose we want to convert the column network to uppercase

def to_uppercase(column):
  return column.upper()

df['Capitalized_title'] = df['title'].apply(to_uppercase)

df.head()

"""## Another way to use <code>apply()</code> involves the use of <code>lambda()</code> function.

* ### A <code>lambda()</code> function is a small anonymous function.
* ### A <code>lambda()</code> function can take any number of arguments, but can only have one expression.
"""

def add_two_numbers(a,b):
  return a+b

x = lambda a,b : a+b
x(1,5)



# lambda function - Row wise operation
def revised_profit(revenue, budget):
  if revenue > 0:
    new_profit = revenue - budget
  else:
    new_profit = np.nan

  return new_profit

df['new_profit'] = df.apply(lambda x: revised_profit(x['revenue'], x['budget']),axis=1)

df.head()

"""## We can also sort our dataframe by some column values in either an ascending or descending order"""

# Sort values in descending order
df.sort_values('runtime', ascending=False)

# We can also sort by the combination of two columns
df.sort_values(['status','new_profit'], ascending=[False,True]).head()

"""# <b>Let us explore some datetime operations and functions

Directive

* #### <b>%a</b>	Weekday as locale’s abbreviated name.	Sun, Mon, …, Sat (en_US)
So, Mo, …, Sa (de_DE)
* #### <b>%A</b>	Weekday as locale’s full name.	Sunday, Monday, …, Saturday (en_US)
Sonntag, Montag, …, Samstag (de_DE)
* #### <b>%w</b>	Weekday as a decimal number, where 0 is Sunday and 6 is Saturday.	0, 1, 2, 3, 4, 5, 6
* #### <b>%d</b>	Day of the month as a zero-padded decimal number.	01, 02, …, 31
* #### <b>%b</b>	Month as locale’s abbreviated name.	Jan, Feb, …, Dec (en_US)
Jan, Feb, …, Dez (de_DE)
* #### <b>%B</b>	Month as locale’s full name.	January, February, …, December (en_US)
Januar, Februar, …, Dezember (de_DE)
* #### <b>%m</b>	Month as a zero-padded decimal number.	01, 02 … 12
* #### <b>%y</b>	Year without century as a zero-padded decimal number.	01, 02, … 99
* #### <b>%Y</b>	Year with century as a decimal number.	0001, 0002, … , 9999
* #### <b>%H</b>	Hour (24-hour clock) as a zero-padded decimal number.	01, 02, … , 23
* #### <b>%I</b>	Hour (12-hour clock) as a zero-padded decimal number.	01, 02, … , 12
* #### <b>%p</b>	Locale’s equivalent of either AM or PM.	AM, PM (en_US)
am, pm (de_DE)
* #### <b>%M</b>	Minute as a zero-padded decimal number.	01, 02, … , 59
* #### <b>%S</b>	Second as a zero-padded decimal number.	01, 02, … , 59
* #### <b>%f</b>	Microsecond as a decimal number, zero-padded on the left.	000000, 000001, …, 999999
"""

df.info()

df['release_date'][0:5]

# Importing datetime modules
from datetime import datetime
from datetime import date

"""## <code>strptime</code> means string parser, this will convert a string format to datetime.

## <code>strftime</code> means string formatter, this will format a datetime object to string format.
"""

df['release_date'][0:5]

df['new_release_date']=df['release_date'].apply(lambda x : datetime.strptime(x,'%m/%d/%y'))

df.info()

df.head()

df['new_release_date'][0]

# Month year date
print(df['new_release_date'][0].month)
print(df['new_release_date'][0].year)
print(df['new_release_date'][0].day)
print(df['new_release_date'][0].hour)
print(df['new_release_date'][0].minute)

print(date.today())
print(datetime.now())

datetime.now() + 1

# Some operations we can do on datetime
from datetime import timedelta
print(date.today())
print(date.today() - timedelta(days=1))
print(datetime.now() + timedelta(hours=5.5))
print(datetime.now() + timedelta(seconds=60))

print(df['new_release_date'][0])
print(df['new_release_date'][5])

# Difference in two datetime
time_delta=df['new_release_date'][0]-df['new_release_date'][5]
time_delta

type(time_delta)

time_delta.total_seconds()

t1 = pd.to_datetime('1/1/2015 01:00')
t2 = pd.to_datetime('1/1/2015 03:30')

print(pd.Timedelta(t2 - t1).seconds / 3600.0)

"""# **Let's explore the unique and missing values**

* ### <code>unique()</code>
* ### <code>nunique()</code>
* ### <code>value_counts()</code>
* ### <code>isnull()</code>
* ### <code>fillna()</code>
"""

df.info()

# Find the list of unique values in a column
list(df['status'].unique())

list(df['original_language'].unique())

# Counts the number of unique values in a column
df.original_language.nunique()

# Give the counts of each category of a variable
df['original_language'].value_counts()

# Does not make much sense to use value_counts for a numeric variable
df.runtime.value_counts()

# Returns a series of booleans if a column value contains nulls
df['homepage'].isnull()

df[~df['homepage'].isnull()]

# Lets fill the missing values with the value -999
df['homepage'].fillna('Not Present',inplace = True)

df.head()

import pandas as pd

imdb_df=pd.read_csv('/content/drive/MyDrive/New Folder/Rahul Ameta/imdb_data.csv')

imdb_df.head()

imdb_df.shape

imdb_df.info()

df=imdb_df.copy()

df.describe()

df.iloc[1:5,-3:]

df2=df.loc[1:10,['original_language','budget']]
df2

df['original_language'] =='en'

